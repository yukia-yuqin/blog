---
layout: post
title: 机器学习面试
tags: interview
categories: interview
---
记录一下网上扒下来的以及自己的面试经历。<br>

### 技术面问题
- fast rcnn
- adaboost 
- gbdt 
- XGBOOST 
   - xgboost，在求解速度，对异常值处理上要比gbdt要快
- random forest
- lgb
- 神经网络embedding层和w2v中的embedding的实现区别
- L1、L2的区别，L1为什么可以保证稀疏？
- 深度学习的优化方法有哪些？ sgd、adam、adgrad区别？ adagrad详细说一下？为什么adagrad适合处理稀疏梯度？ 
- DL常用的激活函数有哪些？ 
- relu和sigmoid有什么区别，优点有哪些？ 
- 什么是梯度消失，标准的定义是什么？ 
- DNN的初始化方法有哪些？ 为什么要做初始化？ kaiming初始化方法的过程是怎样的？ 
- xgboost里面的lambdarank的损失函数是什么？ 
- xgboost在什么地方做的剪枝，怎么做的？ 
- xgboost如何分布式？特征分布式和数据分布式？ 各有什么存在的问题？ 
- lightgbm和xgboost有什么区别？他们的loss一样么？ 算法层面有什么区别？ 
- lightgbm有哪些实现，各有什么区别？
- EM
- LDA
- 要懂得算法的推导、适用场景、使用的Trick、分布式实现
- CNN、RNN、LSTM的基本原理，不同激活函数的差异等等，如果是面的传统机器学习岗的话，DL问的不深，但一定会问。